{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu0p5OLpSAg2",
        "outputId": "1d5ce753-4a53-4721-fd2e-d5a0f0a2f1af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu | num_classes: 8\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torchvision import models\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_classes = 8\n",
        "print(\"Device:\", device, \"| num_classes:\", num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Y5L9t-RrQjKP"
      },
      "outputs": [],
      "source": [
        "train_data = torch.load(\"isic_train_xy.pt\")\n",
        "test_data  = torch.load(\"isic_test_xy.pt\")\n",
        "\n",
        "train_X, train_y = train_data[\"X\"], train_data[\"y\"]\n",
        "test_X,  test_y  = test_data[\"X\"],  test_data[\"y\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEcisiJQo03i"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvnaAmmLVj1k",
        "outputId": "d86ddba5-cce7-4e24-ddb0-64d8d98be62a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch x: torch.Size([256, 3, 224, 224]) batch y: torch.Size([256])\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "NUM_WORKERS = 2  # set 0 if Colab errors\n",
        "\n",
        "train_ds = TensorDataset(train_X, train_y)\n",
        "test_ds  = TensorDataset(test_X,  test_y)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "# sanity\n",
        "x, y = next(iter(train_loader))\n",
        "print(\"batch x:\", x.shape, \"batch y:\", y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyYuLgI0o223"
      },
      "source": [
        "#Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Loh8ArsiVW77"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, loader):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        correct += (logits.argmax(1) == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "    return total_loss / total, correct / total\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    total_loss, correct, total = 0.0, 0, 0\n",
        "    all_preds, all_true = [], []\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        preds = logits.argmax(1)\n",
        "\n",
        "        correct += (preds == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "        all_preds.append(preds.cpu().numpy())\n",
        "        all_true.append(y.cpu().numpy())\n",
        "\n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_true  = np.concatenate(all_true)\n",
        "    return total_loss / total, correct / total, all_true, all_preds\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n89hAEj5oHx8"
      },
      "source": [
        "# Resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XWOsN3to8GE",
        "outputId": "afdc9d32-1801-4b2d-dcbc-513be5e0b8af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=512, out_features=9, bias=True)\n"
          ]
        }
      ],
      "source": [
        "from torchvision import models\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_classes = 9\n",
        "\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Replace final fully connected layer\n",
        "in_features = model.fc.in_features\n",
        "model.fc = nn.Linear(in_features, num_classes)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.fc.requires_grad = True\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "print(model.fc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "8JfELX_7VMR7"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"max\", patience=2, factor=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    tr_loss, tr_acc = train_one_epoch(model, train_loader)\n",
        "    va_loss, va_acc, _, _ = evaluate(model, test_loader)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch:02d} | \"\n",
        "        f\"train loss {tr_loss:.4f} acc {tr_acc:.4f} | \"\n",
        "        f\"test loss {va_loss:.4f} acc {va_acc:.4f}\"\n",
        "    )\n",
        "\n",
        "    if va_acc > best_acc:\n",
        "        best_acc = va_acc\n",
        "        torch.save(model.state_dict(), \"best_model.pt\")\n",
        "        print(f\"nSaved new best model (test acc = {best_acc:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "fIfI6FAsNV8n",
        "outputId": "f4c7edad-8b9d-4a1b-a111-c8b4af1505fc"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'collections.OrderedDict' object has no attribute 'train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3150791243.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mva_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1779642003.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'train'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTkjoHDWJxyL"
      },
      "source": [
        "# Efficient Net B0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlOCzrU2JxQz",
        "outputId": "8952ec08-c7ef-42d3-fbdf-4b58514b9592"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 195MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Dropout(p=0.2, inplace=True)\n",
            "  (1): Linear(in_features=1280, out_features=8, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# EfficientNet-B0 (ImageNet pretrained)\n",
        "num_classes = 8\n",
        "\n",
        "model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Replace classifier head\n",
        "in_features = model.classifier[1].in_features\n",
        "model.classifier[1] = nn.Linear(in_features, num_classes)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.classifier[1].requires_grad = True\n",
        "model = model.to(device)\n",
        "print(model.classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "ANbUDlemKIlJ",
        "outputId": "31e820d3-1a7f-4b2a-c570-7f0d63a34521"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-614292783.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mva_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1779642003.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_res_connect\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic_depth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             )\n\u001b[0;32m--> 543\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    544\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "EPOCHS = 5\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    tr_loss, tr_acc = train_one_epoch(model, train_loader)\n",
        "    va_loss, va_acc, y_true, y_pred = evaluate(model, test_loader)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch:02d} | \"\n",
        "        f\"train loss {tr_loss:.4f} acc {tr_acc:.4f} | \"\n",
        "        f\"test loss {va_loss:.4f} acc {va_acc:.4f}\"\n",
        "    )\n",
        "\n",
        "    # simple early stopping: stop when accuracy stops improving\n",
        "    if va_acc <= best_acc:\n",
        "        print(\"Early stopping triggered\")\n",
        "        break\n",
        "\n",
        "    best_acc = va_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wBtb0JPKY02"
      },
      "outputs": [],
      "source": [
        "classes = np.unique(y_true)\n",
        "class_acc = []\n",
        "\n",
        "for c in classes:\n",
        "    idx = (y_true == c)\n",
        "    acc_c = (y_pred[idx] == y_true[idx]).mean()\n",
        "    class_acc.append(acc_c)\n",
        "\n",
        "class_acc = np.array(class_acc)\n",
        "\n",
        "if \"id2label\" in globals():\n",
        "    class_names = [id2label[int(c)] for c in classes]\n",
        "else:\n",
        "    class_names = [f\"Class {int(c)}\" for c in classes]\n",
        "\n",
        "order = np.argsort(class_acc)\n",
        "class_acc = class_acc[order]\n",
        "class_names = np.array(class_names)[order]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.barh(class_names, class_acc, color=plt.cm.Blues(class_acc))\n",
        "\n",
        "plt.xlim(0, 1)\n",
        "plt.xlabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy per Class\")\n",
        "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.4)\n",
        "\n",
        "for bar, acc in zip(bars, class_acc):\n",
        "    plt.text(\n",
        "        acc + 0.02,\n",
        "        bar.get_y() + bar.get_height() / 2,\n",
        "        f\"{acc:.2f}\",\n",
        "        va=\"center\",\n",
        "        fontsize=10\n",
        "    )\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MobileNetV2"
      ],
      "metadata": {
        "id": "k5rmo9fXUP3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.IMAGENET1K_V1)\n",
        "\n",
        "# Replace classifier head\n",
        "in_features = model.classifier[1].in_features\n",
        "model.classifier[1] = nn.Linear(in_features, num_classes)\n",
        "\n",
        "model = model.to(device)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.classifier[1].requires_grad = True\n",
        "print(model.classifier)"
      ],
      "metadata": {
        "id": "k4HG6dnBUPmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 5\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    tr_loss, tr_acc = train_one_epoch(model, train_loader)\n",
        "    va_loss, va_acc, y_true, y_pred = evaluate(model, test_loader)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch:02d} | \"\n",
        "        f\"train loss {tr_loss:.4f} acc {tr_acc:.4f} | \"\n",
        "        f\"test loss {va_loss:.4f} acc {va_acc:.4f}\"\n",
        "    )\n",
        "\n",
        "    # simple early stopping: stop when accuracy stops improving\n",
        "    if va_acc <= best_acc:\n",
        "        print(\"Early stopping triggered\")\n",
        "        break\n",
        "\n",
        "    best_acc = va_acc"
      ],
      "metadata": {
        "id": "NQ4C_XTIUl1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = np.unique(y_true)\n",
        "class_acc = []\n",
        "\n",
        "for c in classes:\n",
        "    idx = (y_true == c)\n",
        "    acc_c = (y_pred[idx] == y_true[idx]).mean()\n",
        "    class_acc.append(acc_c)\n",
        "\n",
        "class_acc = np.array(class_acc)\n",
        "\n",
        "if \"id2label\" in globals():\n",
        "    class_names = [id2label[int(c)] for c in classes]\n",
        "else:\n",
        "    class_names = [f\"Class {int(c)}\" for c in classes]\n",
        "\n",
        "order = np.argsort(class_acc)\n",
        "class_acc = class_acc[order]\n",
        "class_names = np.array(class_names)[order]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.barh(class_names, class_acc, color=plt.cm.Blues(class_acc))\n",
        "\n",
        "plt.xlim(0, 1)\n",
        "plt.xlabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy per Class\")\n",
        "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.4)\n",
        "\n",
        "for bar, acc in zip(bars, class_acc):\n",
        "    plt.text(\n",
        "        acc + 0.02,\n",
        "        bar.get_y() + bar.get_height() / 2,\n",
        "        f\"{acc:.2f}\",\n",
        "        va=\"center\",\n",
        "        fontsize=10\n",
        "    )\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hzpOJtRGUsMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Our Model"
      ],
      "metadata": {
        "id": "l-XFqvwZVpvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class DropPath(nn.Module):\n",
        "    def __init__(self, drop_prob=0.0):\n",
        "        super().__init__()\n",
        "        self.drop_prob = float(drop_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.drop_prob == 0.0 or not self.training:\n",
        "            return x\n",
        "        keep_prob = 1.0 - self.drop_prob\n",
        "        shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # (B,1,1,1)\n",
        "        rand = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
        "        mask = torch.floor(rand)\n",
        "        return x / keep_prob * mask\n",
        "\n",
        "\n",
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, ch, r=16):\n",
        "        super().__init__()\n",
        "        hidden = max(8, ch // r)\n",
        "        self.fc1 = nn.Conv2d(ch, hidden, kernel_size=1, bias=True)\n",
        "        self.fc2 = nn.Conv2d(hidden, ch, kernel_size=1, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        s = F.adaptive_avg_pool2d(x, 1)\n",
        "        s = F.relu(self.fc1(s), inplace=True)\n",
        "        s = torch.sigmoid(self.fc2(s))\n",
        "        return x * s\n",
        "\n",
        "class PreActSEBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, stride=1, drop_path=0.0, se_r=16):\n",
        "        super().__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_ch)\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False)\n",
        "\n",
        "        self.se = SEBlock(out_ch, r=se_r)\n",
        "        self.dp = DropPath(drop_path)\n",
        "\n",
        "        self.shortcut = nn.Identity()\n",
        "        if stride != 1 or in_ch != out_ch:\n",
        "            self.shortcut = nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.silu(self.bn1(x), inplace=True)\n",
        "        shortcut = self.shortcut(out)  # pre-act shortcut\n",
        "\n",
        "        out = self.conv1(out)\n",
        "        out = self.conv2(F.silu(self.bn2(out), inplace=True))\n",
        "        out = self.se(out)\n",
        "        out = self.dp(out)\n",
        "        return out + shortcut\n",
        "\n",
        "\n",
        "class OurModel(nn.Module):\n",
        "    def __init__(self, num_classes=8, width=48, layers=(2, 2, 2, 2), drop_path_rate=0.15):\n",
        "        super().__init__()\n",
        "        self.in_ch = width\n",
        "\n",
        "        # medical images often do better with a smaller stem than 7x7\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, width, kernel_size=3, stride=2, padding=1, bias=False),  # 224->112\n",
        "            nn.BatchNorm2d(width),\n",
        "            nn.SiLU(inplace=True),\n",
        "            nn.Conv2d(width, width, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(width),\n",
        "            nn.SiLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  # 112->56\n",
        "        )\n",
        "\n",
        "        total_blocks = sum(layers)\n",
        "        dp_rates = torch.linspace(0, drop_path_rate, total_blocks).tolist()\n",
        "        dp_i = 0\n",
        "\n",
        "        self.layer1 = self._make_layer(width,   layers[0], stride=1, dp_rates=dp_rates, dp_i=dp_i); dp_i += layers[0]\n",
        "        self.layer2 = self._make_layer(width*2, layers[1], stride=2, dp_rates=dp_rates, dp_i=dp_i); dp_i += layers[1]\n",
        "        self.layer3 = self._make_layer(width*4, layers[2], stride=2, dp_rates=dp_rates, dp_i=dp_i); dp_i += layers[2]\n",
        "        self.layer4 = self._make_layer(width*6, layers[3], stride=2, dp_rates=dp_rates, dp_i=dp_i); dp_i += layers[3]\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(self.in_ch, num_classes)\n",
        "        )\n",
        "\n",
        "    def _make_layer(self, out_ch, blocks, stride, dp_rates, dp_i):\n",
        "        layers = []\n",
        "        for b in range(blocks):\n",
        "            s = stride if b == 0 else 1\n",
        "            layers.append(\n",
        "                PreActSEBlock(\n",
        "                    self.in_ch, out_ch, stride=s,\n",
        "                    drop_path=dp_rates[dp_i + b],\n",
        "                    se_r=16\n",
        "                )\n",
        "            )\n",
        "            self.in_ch = out_ch\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.pool(x).flatten(1)\n",
        "        return self.head(x)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xsHHSLGCVxYC"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = OurModel(num_classes=8).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"max\", patience=2, factor=0.5)"
      ],
      "metadata": {
        "id": "QQa_4QNmWmx_"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OsGSiimhE1q",
        "outputId": "cc6d0c86-6fe2-4c12-c927-f96ef60070c9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OurModel(\n",
              "  (stem): Sequential(\n",
              "    (0): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): SiLU(inplace=True)\n",
              "    (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): SiLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer1): Sequential(\n",
              "    (0): PreActSEBlock(\n",
              "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (se): SEBlock(\n",
              "        (fc1): Conv2d(48, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (fc2): Conv2d(8, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (dp): DropPath()\n",
              "      (shortcut): Identity()\n",
              "    )\n",
              "    (1): PreActSEBlock(\n",
              "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (se): SEBlock(\n",
              "        (fc1): Conv2d(48, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (fc2): Conv2d(8, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (dp): DropPath()\n",
              "      (shortcut): Identity()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): PreActSEBlock(\n",
              "      (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (se): SEBlock(\n",
              "        (fc1): Conv2d(96, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (fc2): Conv2d(8, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (dp): DropPath()\n",
              "      (shortcut): Conv2d(48, 96, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "    )\n",
              "    (1): PreActSEBlock(\n",
              "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (se): SEBlock(\n",
              "        (fc1): Conv2d(96, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (fc2): Conv2d(8, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (dp): DropPath()\n",
              "      (shortcut): Identity()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): PreActSEBlock(\n",
              "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (se): SEBlock(\n",
              "        (fc1): Conv2d(192, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (fc2): Conv2d(12, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (dp): DropPath()\n",
              "      (shortcut): Conv2d(96, 192, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "    )\n",
              "    (1): PreActSEBlock(\n",
              "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (se): SEBlock(\n",
              "        (fc1): Conv2d(192, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (fc2): Conv2d(12, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (dp): DropPath()\n",
              "      (shortcut): Identity()\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): PreActSEBlock(\n",
              "      (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(192, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (se): SEBlock(\n",
              "        (fc1): Conv2d(288, 18, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (fc2): Conv2d(18, 288, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (dp): DropPath()\n",
              "      (shortcut): Conv2d(192, 288, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "    )\n",
              "    (1): PreActSEBlock(\n",
              "      (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv1): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (se): SEBlock(\n",
              "        (fc1): Conv2d(288, 18, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (fc2): Conv2d(18, 288, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (dp): DropPath()\n",
              "      (shortcut): Identity()\n",
              "    )\n",
              "  )\n",
              "  (pool): AdaptiveAvgPool2d(output_size=1)\n",
              "  (head): Sequential(\n",
              "    (0): Dropout(p=0.4, inplace=False)\n",
              "    (1): Linear(in_features=288, out_features=8, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    tr_loss, tr_acc = train_one_epoch(model, train_loader)\n",
        "    te_loss, te_acc, y_true, y_pred = evaluate(model, test_loader)\n",
        "\n",
        "    scheduler.step(te_acc)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch:02d} | \"\n",
        "        f\"train loss {tr_loss:.4f} acc {tr_acc:.4f} | \"\n",
        "        f\"test loss {te_loss:.4f} acc {te_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "9rI8X0MCWpQp",
        "outputId": "f41fc928-1a05-45f2-9fdb-fccd324a5cab"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-136233289.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mte_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1779642003.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2061730697.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             )\n\u001b[0;32m--> 543\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    544\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state = torch.load(\"best_model.pt\", map_location=device)\n",
        "model.load_state_dict(state)\n",
        "loss, acc, y_true, y_pred = evaluate(model, test_loader)\n",
        "\n",
        "print(f\"Accuracy: {acc:.4f}\")"
      ],
      "metadata": {
        "id": "RUYkWALOgBiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "classes = np.unique(y_true)\n",
        "class_acc = []\n",
        "\n",
        "for c in classes:\n",
        "    idx = (y_true == c)\n",
        "    acc_c = (y_pred[idx] == y_true[idx]).mean()\n",
        "    class_acc.append(acc_c)\n",
        "\n",
        "class_acc = np.array(class_acc)\n",
        "\n",
        "if \"id2label\" in globals():\n",
        "    class_names = [id2label[int(c)] for c in classes]\n",
        "else:\n",
        "    class_names = [f\"Class {int(c)}\" for c in classes]\n",
        "\n",
        "order = np.argsort(class_acc)\n",
        "class_acc = class_acc[order]\n",
        "class_names = np.array(class_names)[order]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.barh(class_names, class_acc, color=plt.cm.Blues(class_acc))\n",
        "\n",
        "plt.xlim(0, 1)\n",
        "plt.xlabel(\"Accuracy\")\n",
        "plt.title(\"Accuracy per Class\")\n",
        "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.4)\n",
        "\n",
        "for bar, acc in zip(bars, class_acc):\n",
        "    plt.text(\n",
        "        acc + 0.02,\n",
        "        bar.get_y() + bar.get_height() / 2,\n",
        "        f\"{acc:.2f}\",\n",
        "        va=\"center\",\n",
        "        fontsize=10\n",
        "    )\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "vq1kLluXBxXC",
        "outputId": "27e20b53-62b2-4093-90b3-01a5f4654d69"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}